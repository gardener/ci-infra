apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: prow-k8s-apps
  namespace: monitoring
  labels:
    prometheus: prow-k8s-apps
    role: alert-rules
spec:
  groups:
  - name: prow-k8s-apps
    rules:
    # This is same alert as upstream's KubePodNotReady, but it completely ignores the test-pods namespace.
    # We do not care about failing pods in this namespace, i.e., failing tests. They are taking care of via other means than alerts.
    - alert: KubePodNotReady
      annotations:
        description: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepodnotready
        summary: Pod has been in a non-ready state for more than 15 minutes.
      expr: |
        sum by (namespace, pod, cluster) (max by (namespace, pod, cluster) (kube_pod_status_phase{job="kube-state-metrics",phase=~"Pending|Unknown|Failed", namespace!="test-pods"}) * on (namespace, pod, cluster) group_left (owner_kind) topk by (namespace, pod, cluster) (1, max by (namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job", namespace!="test-pods"}))) > 0
      for: 15m
      labels:
        severity: warning
    # This is same alert as upstream's KubeContainerWaiting, but it completely ignores the test-pods namespace.
    # We do not care about failing pods in this namespace, i.e., failing tests. They are taking care of via other means than alerts.
    - alert: KubeContainerWaiting
      annotations:
        description: Container {{ $labels.container }} of Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in waiting state for longer than 1 hour.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubecontainerwaiting
        summary: Pod container has been in waiting longer than 1 hour
      expr: sum by (namespace, pod, container, cluster) (kube_pod_container_status_waiting_reason{job="kube-state-metrics", namespace!="test-pods"}) > 0
      for: 1h
      labels:
        severity: warning
  - name: prow-k8s-system-kubelet
    rules:
    # The upstream chart has two KubeletClientCertificateExpiration alerts, one with severity warning when the
    # certificate is about to expire in less than a week, and one critical alert for less than a day.
    # This alert is only the second one but with a lower severity.
    # Gardener uses rather short certificate lifetimes, hence they are renewed shorter before expiration than the
    # kube-prometheus-stack expects.
    - alert: KubeletClientCertificateExpiration
      annotations:
        description: Client certificate for Kubelet on node {{ $labels.node }} expires
          in {{ $value | humanizeDuration }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletclientcertificateexpiration
        summary: Kubelet client certificate is about to expire.
      expr: kubelet_certificate_manager_client_ttl_seconds < 86400
      labels:
        severity: high
    - alert: KubeletServerCertificateExpiration
      annotations:
        description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletservercertificateexpiration
        summary: Kubelet server certificate is about to expire.
      expr: |
        kubelet_certificate_manager_server_ttl_seconds < 86400
      labels:
        severity: critical
